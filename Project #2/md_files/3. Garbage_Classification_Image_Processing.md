# 2022-1_DTA_Garbage_Classification

​	

# Garbage Classification Image Processing

2022.06.17. Fri

​	

Handong Global University, School of Mechanical and Control Engineering, 2022-1 DigitalTwin&Automation

21500018 | 강희윤

21700791 | 홍세현

21900726 | 지현빈

​	

​	

## Dataset

**Raw Dataset** :: Kaggle Garbage Classification Dataset, Click [Here](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/dataset.zip)

**Raw Class** :: cardboard, glass, metal , paper, plastic and trash.
                ![image](https://user-images.githubusercontent.com/84533279/174222867-df0cf686-f110-457b-9e28-ffaa8bc6f916.png)

​	

​

단, 이번 프로젝트에서는 *Can, Plastic, Cardboard*에 대한 Multi-Classification이 목표였기 때문에 이에 따라 데이터셋을 적절히 수정하였으며 파일이름을 '**dataset_fit**'으로 명명하였습니다. 따라서, 본 프로젝트를 동일하게 수행하기 위해서는 하단의 **Modified Dataset(dataset_fit)** 을 다운로드 받아야 합니다.

**Modified Dataset** :: Modified Kaggle Garbage Classification Dataset, Click [Here](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/dataset_fit.zip)

**Modified Class** :: cardboard, metal, and plastic.

​	

**dataset_fit.zip** 파일을 다운로드 받으면 아래와 같이 3가지 Garbage Type을 확인할 수 있으며, 각 Type의 폴더 안에는 Garbage Image가 '**Type이름 + Index Number.jpg**' 형식으로 되어있음을 확인할 수 있습니다.

![image](https://user-images.githubusercontent.com/84533279/174445002-bd3fcca2-3443-4ff6-9ac3-07c81fabb69d.png)

​	

참고로, zip 파일의 압축 해제와 Train Data / Validation Data Split 및 Model 저장 등 모든 과정은 **[2. Garbage_Classification_ImageProcessing](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/tree/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing)** 에 존재하는 **[1. Get_Model_Garbage_Three_Class_Classification.ipynb](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/1.%20Get_Model_Garbage_Three_Class_Classification.ipynb)** 파이썬 코드 상에서 진행하였습니다. 따라서, 다운로드 받은 **dataset_fit.zip** 파일은 따로 압축 해제 할 필요 없이 하단의 사진에서 보실 수 있듯이 **[2. Garbage_Classification_ImageProcessing](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/tree/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing)** 폴더에 넣어주면 됩니다.
​	![image](https://user-images.githubusercontent.com/84533279/174444881-82b5c411-499d-4f72-a285-7de761613f6a.png)

​	

Train / Validation Dataset이 준비되었다면, 다음과 같이 **Dataset_fit.zip** 파일과 동일한 경로에 **Random_Test_Image** 폴더를 추가하도록 합니다.
![image](https://user-images.githubusercontent.com/84533279/174445040-f91b34e9-4cb9-4671-acd8-1a2769af7107.png)

이 파일에는 Test Image로 사용하고 싶은 Garbage사진을 넣어주면 됩니다.
임의로 촬영한 쓰레기 사진도 좋고, 인터넷 상에서 가져온 임의의 Garbage Image도 좋습니다. 단, 다음과 규칙을 따라야 합니다.
  1. *Can, Plastic, Cardboard* 에 속하는 이미지만 사용해야 합니다.
  2. 동시에 여러 Class를 예측할 수 없으므로 하나의 이미지에 하나의 Garbage Object만 존재해야 합니다.
  3. Random_Test_Image폴더에 들어가는 사진의 이름은 '**Type이름 + Index Number.jpg**'형식을 가져야 합니다. 이는, 파일명에 존재하는 'Type이름'을 토대로 Test Image의 Label Class를 추출하고, Prediction값과 비교하여 모델의 성능을 평가하기 위함입니다.

![image](https://user-images.githubusercontent.com/84533279/174256978-91b5f57a-f6d2-4207-8775-85655b8c7e4f.png)

​


## Define and Train Garbage Classification Model

앞 과정을 통해모든 Dataset이 준비되었다면, Garbage Classification을 위한 Model을 정의하면 됩니다.

모델 정의 과정은 다음의 Flow를 따라 진행하였습니다.

![FlowChart_ModelTraining](https://user-images.githubusercontent.com/84533279/174445834-759a9a81-b9c6-4ed7-866d-e2a0fb506cfd.jpg)

​

■ 1. Import Libraries & Version Checking
![image](https://user-images.githubusercontent.com/84533279/174446378-0286dacb-1e96-4b26-99cd-a174b37bae41.png)

![image](https://user-images.githubusercontent.com/84533279/174446401-b69b29d8-2c3b-4966-b87e-fe6c5d1e3455.png)

![image](https://user-images.githubusercontent.com/84533279/174446423-b008550d-4ae1-4850-96b2-81f1b5c58671.png)

설명하자면, 본 프로젝트에서는 다음과 같은 환경에서 이미지 영상 처리를 진행하였습니다.

![image](https://user-images.githubusercontent.com/84533279/174446228-ba8bbe0a-d8a6-417f-b944-399a7acb2606.png)

특히, FastAI의 경우에는 현재 version 2.X가 나와있지만, 본 프로젝트에서 사용하고 있는 FastAI의 내장함수를 이용하기 위해서는 반드시 version 1.0.61을 사용해야 합니다.

fastAI 1.0.61을 설치하기 위해서는 다음의 코드를 추가하여 실행하면 됩니다.

**pip install fastai==1.0.61**

또한, NVIDIA GeForce RTX 3060 Laptop GPU cuda device 환경에서 Model Training이 진행되었습니다.

​

■ 2. Function Define 

본 프로젝트에서는 Data Split과 학습 환경 셋팅을 위해 4개의 함수를 정의하였습니다.

**2-1. Split Indices**

![image](https://user-images.githubusercontent.com/84533279/174446498-423a5133-b826-4731-bfb6-2bbe81cc5a52.png)

파일의 이름은 ‘ **Type이름 + Index Number.jpg** ’ 로 이루어져 있는데, Split indices함수는 Dataset에서 Train Data 와 Valid Data로 사용할 데이터의 인덱스를 랜덤하게 뽑아주는 함수입니다. 폴더 내에 존재하는 모든 파일의 개수를 읽어오고, 개수 범위 내에서 80%를 랜덤하게 뽑아서 Train Data의 index로, 나머지 20%를 Validation Data의 index로 정의했습니다. Test Data는 따로 나누지 않았는데, 이는 임의로 찍은 사진이나 인터넷에서 가져온 사진을 Test Data로 사용하기 위함입니다.

​

**2-2. Get names**

![image](https://user-images.githubusercontent.com/84533279/174447109-baa945dc-4d6e-4357-9b53-c4e18cfbdc5c.png)

Get names 함수는 split indices 함수에서 정의한 train data index와 validation data index를 바탕으로, Train data 및 validation data로 사용할 이미지의 파일 이름 전체를 반환해주는 함수입니다.

​

**2-3. move files**

![image](https://user-images.githubusercontent.com/84533279/174447120-a88dc996-cd95-4135-87af-57f2e228c7be.png)

Split Indices 함수와 Get names 함수를 통해 얻은 파일의 이름들을 바탕으로, Train Data에 해당하는 이미지는 Train Folder로, Validation Data에 해당하는 이미지는 Valid Folder로 이동시켜야 했으며 이 기능을 Move files 함수로 구현하였습니다.

​

**2-4. DeleteAllFiles**

![image](https://user-images.githubusercontent.com/84533279/174447128-e872c206-6770-4b97-8fb7-0bb6736e5263.png)

또한, Test Data의 경우에는 새로운 Test Data Image가 주어지면 기존 Image는 제거한 채, 새로운 이미지에 대해서만 Prediction 하도록 해야했기에 DeleteAllFiles함수를 정의하여 실행할 때마다 특정 폴더내의 모든 파일을 제거하도록 했습니다.

​

■ 3. Data Loading & Unzip Kaggle Dataset

Python Code 상에서 ALzip을 Unzip하였습니다.
![image](https://user-images.githubusercontent.com/84533279/174447194-5121130c-b2b2-4d82-9cff-0fe0aba3e720.png)

​

'Dataset_fit.zip'파일을 Unzip함으로써 생성된 Dataset_fit파일 내에 존재하는 모든 파일과 폴더의 이름을 추출하였습니다.
이를 통해, 'Dataset_fit.zip'에 존재하는 Class Type을 Python Code상에서 검토 및 확인할 수 있습니다.
![image](https://user-images.githubusercontent.com/84533279/174447208-61bf6746-f71f-43d4-8146-612e04cbc9fe.png)

​


![image](https://user-images.githubusercontent.com/84533279/174447355-97ea7015-7780-4553-a27e-3ba05705e5f4.png)

​

■ 4. Split Train / Validation Data

​

■ 5. Test Data Folder Clearing & Test Data Resize

​

■ 6. Data Transform by FastAI Library

​

■ 7. Model Training by Resnet34

​

■ 8. Apply Model to Resized Test Data

​

■ 9. Model Save

​



  
