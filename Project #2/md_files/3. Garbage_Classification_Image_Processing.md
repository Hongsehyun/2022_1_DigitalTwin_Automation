# 2022-1_DTA_Garbage_Classification

​	

# Garbage Classification Image Processing

2022.06.17. Fri

​	

Handong Global University, School of Mechanical and Control Engineering, 2022-1 DigitalTwin&Automation

21500018 | 강희윤

21700791 | 홍세현

21900726 | 지현빈

​	

​	

​	

## Dataset

​		**■ Raw Dataset** :: Kaggle Garbage Classification Dataset, Click [Here](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/dataset.zip)

​		**■ Raw Class** :: cardboard, glass, metal , paper, plastic and trash.
​                ![image](https://user-images.githubusercontent.com/84533279/174222867-df0cf686-f110-457b-9e28-ffaa8bc6f916.png)

​	

​	

단, 이번 프로젝트에서는 *Can, Plastic, Cardboard*에 대한 Multi-Classification이 목표였습니다.

이에 따라 데이터셋을 적절히 수정하였으며 파일이름을 '**dataset_fit**'으로 명명하였습니다.

따라서, 본 프로젝트를 동일하게 수행하기 위해서는 하단의 **Modified Dataset(dataset_fit)** 을 다운로드 받아야 합니다.

​	

​		**■ Modified Dataset** :: Modified Kaggle Garbage Classification Dataset, Click [Here](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/dataset_fit.zip)

​		**■ Modified Class** :: cardboard, metal, and plastic.

​	

**dataset_fit.zip** 파일을 다운로드 받으면 아래와 같이 3가지 Garbage Type을 확인할 수 있으며,

각 Type의 폴더 안에는 Garbage Image가 '**Type이름 + Index Number.jpg**' 형식으로 되어있음을 확인할 수 있습니다.

![image](https://user-images.githubusercontent.com/84533279/174445002-bd3fcca2-3443-4ff6-9ac3-07c81fabb69d.png)

​	

​	

참고로, zip 파일의 압축 해제와 Train Data / Validation Data Split 및 Model 저장 등 모든 과정은

**[2. Garbage_Classification_ImageProcessing](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/tree/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing)** 에 존재하는 **[1. Get_Model_Garbage_Three_Class_Classification.ipynb](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing/1.%20Get_Model_Garbage_Three_Class_Classification.ipynb)** 파이썬 코드 상에서 진행하였습니다.

​	

따라서, 다운로드 받은 **dataset_fit.zip** 파일은 따로 압축 해제 할 필요 없이 하단의 사진에서 보실 수 있듯이

**[2. Garbage_Classification_ImageProcessing](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/tree/main/Project%20%232/2.%20Garbage_Classification_ImageProcessing)** 폴더에 넣어주면 됩니다.
​	![image](https://user-images.githubusercontent.com/84533279/174444881-82b5c411-499d-4f72-a285-7de761613f6a.png)

​	

Train / Validation Dataset이 준비되었다면, 다음과 같이 **Dataset_fit.zip** 파일과 동일한 경로에 **Random_Test_Image** 폴더를 추가하도록 합니다.
![image](https://user-images.githubusercontent.com/84533279/174445040-f91b34e9-4cb9-4671-acd8-1a2769af7107.png)

이 파일에는 Test Image로 사용하고 싶은 Garbage사진을 넣어주면 됩니다.

임의로 촬영한 쓰레기 사진도 좋고, 인터넷 상에서 가져온 임의의 Garbage Image도 좋습니다. 단, 다음과 규칙을 따라야 합니다.

  1. *Can, Plastic, Cardboard* 에 속하는 이미지만 사용해야 합니다.
  2. 동시에 여러 Class를 예측할 수 없으므로 하나의 이미지에 하나의 Garbage Object만 존재해야 합니다.
  3. Random_Test_Image폴더에 들어가는 사진의 이름은 '**Type이름 + Index Number.jpg**'형식을 가져야 합니다. 이는, 파일명에 존재하는 'Type이름'을 토대로 Test Image의 Label Class를 추출하고, Prediction값과 비교하여 모델의 성능을 평가하기 위함입니다.

![image](https://user-images.githubusercontent.com/84533279/174256978-91b5f57a-f6d2-4207-8775-85655b8c7e4f.png)

​	

​	

​	


## Define and Train Garbage Classification Model

앞 과정을 통해모든 Dataset이 준비되었다면, Garbage Classification을 위한 Model을 정의하면 됩니다.

모델 정의 과정은 다음의 Flow를 따라 진행하였습니다.

![FlowChart_ModelTraining](https://user-images.githubusercontent.com/84533279/174445834-759a9a81-b9c6-4ed7-866d-e2a0fb506cfd.jpg)

참고로, 위의 Flow가 진행된 Python Code는 '**1. Get_Model_Garbage_Three_Class_Classification.ipynb**'에서 확인하실 수 있습니다.

![image](https://user-images.githubusercontent.com/84533279/174454602-0e8dba51-507b-494a-a903-e8c84ac76bf1.png)

​		

​		

##### **■ 1. Import Libraries & Version Checking**

![image](https://user-images.githubusercontent.com/84533279/174450765-30e673c8-1bad-436a-b386-391ded21dc93.png)

![image](https://user-images.githubusercontent.com/84533279/174450774-14072b6d-eab5-4427-af96-2471d77795e6.png)

![image](https://user-images.githubusercontent.com/84533279/174450783-761ff148-7246-4b9e-abaf-82c4ac687b2a.png)

설명하자면, 본 프로젝트에서는 다음과 같은 환경에서 이미지 영상 처리를 진행하였습니다.

![image](https://user-images.githubusercontent.com/84533279/174446228-ba8bbe0a-d8a6-417f-b944-399a7acb2606.png)

특히, FastAI의 경우에는 현재 version 2.6.3까지 출시되어있지만,

본 프로젝트에서 사용하고 있는 FastAI의 내장함수를 이용하기 위해서는 **반드시 version 1.0.61을 사용해야 합니다** .

fastAI 1.0.61을 설치하기 위해서는 다음의 코드를 추가하여 실행하면 됩니다.

`pip install fastai==1.0.61`

​	

추가로, 본 프로젝트는 **NVIDIA GeForce RTX 3060 Laptop GPU cuda device** 환경에서 Model Training이 진행되었습니다.

​	

​	

##### **■ 2. Function Define**

본 프로젝트에서는 Data Split과 학습 환경 셋팅을 위해 4개의 함수를 정의하였습니다.

​	

**2-1. Split Indices**

![image](https://user-images.githubusercontent.com/84533279/174450802-41763148-1200-43c2-baa2-9bc117c2b71a.png)

파일의 이름은 ‘ **Type이름 + Index Number.jpg** ’ 로 이루어져 있는데,

*Split indices*함수는 Dataset에서 Train Data 와 Valid Data로 사용할 데이터의 인덱스를 랜덤하게 뽑아주는 함수입니다.

​	

폴더 내에 존재하는 모든 파일의 개수를 읽어오고,

개수 범위 내에서 80%를 랜덤하게 뽑아서 Train Data의 index로, 나머지 20%를 Validation Data의 index로 정의했습니다.

Test Data는 따로 나누지 않았는데, 이는 임의로 찍은 사진이나 인터넷에서 가져온 사진을 Test Data로 사용하기 위함입니다.

​	

​	

**2-2. Get names**

![image](https://user-images.githubusercontent.com/84533279/174450808-001640af-d75e-426c-9ddb-7e458a436de2.png)

*Get names* 함수는 *split indices* 함수에서 정의한 train data index와 validation data index를 바탕으로,

Train data 및 validation data로 사용할 이미지의 파일 이름 전체를 반환해주는 함수입니다.

​	

​	

**2-3. move files**

![image](https://user-images.githubusercontent.com/84533279/174450817-9ac9c8b6-4861-44ee-bf6c-b11d46d5fdf2.png)

*Split Indices* 함수와 *Get names* 함수를 통해 얻은 파일의 이름들을 바탕으로,

Train Data에 해당하는 이미지는 Train Folder로, Validation Data에 해당하는 이미지는 Valid Folder로 이동시켜야 했으며

이 기능을 *Move files* 함수로 구현하였습니다.

​	

​	

**2-4. DeleteAllFiles**

![image](https://user-images.githubusercontent.com/84533279/174450826-f843da9b-ff1e-4b7e-ac4f-e3e32a445ffa.png)

또한, Test Data의 경우에는 새로운 Test Data Image가 주어지면 기존 Image는 제거한 채,

새로운 이미지에 대해서만 Prediction 하도록 해야했기에 *DeleteAllFiles*함수를 정의하여 실행할 때마다 특정 폴더내의 모든 파일을 제거하였습니다.

​	

​	

##### **■ 3. Data Loading & Unzip Kaggle Dataset**

본 프로젝트는 Python Code 상에서 ALzip을 Unzip하였습니다.
![image](https://user-images.githubusercontent.com/84533279/174450838-e9310527-300c-455f-9e13-e9ba57c89b6e.png)

​	

'*Dataset_fit.zip*'파일을 Unzip함으로써 생성된 *Dataset_fit*파일 내에 존재하는 모든 파일과 폴더의 이름을 ***os.listdir***를 통해 추출하였습니다.

이를 통해, '*Dataset_fit.zip*'에 존재하는 Class Type을 Python Code상에서 검토 및 확인할 수 있습니다.
![image](https://user-images.githubusercontent.com/84533279/174450848-f7b951f3-e59a-4b00-a4d1-97097da16813.png)

​	

​	

##### **■ 4. Split Train / Validation Data**

![image](https://user-images.githubusercontent.com/84533279/174450854-78364bc6-7818-464d-9a92-99fc0e987767.png)

10~16행을 통해서, '*dataset_fit.zip*'의 경로에 'data/train/cardboard', 'data/valid/metal' ... 과 같은 폴더를 생성시킵니다.

이를 통해, 앞서 *Split Indices*함수 및 *get names*함수로 무작위 분리한 Train Data와 Validation Data를 Class별로 구분시킬 수 있습니다.

​	

특히, 23~24행을 통해서는 'data/test'폴더를 생성하는데,

Test를 할때는 임의의 Image에 대해 해당 Image가 plastic인지, metal인지를 구분해야 하기 때문에 'data/test'에 대해서는 쓰레기 타입 폴더를 따로 지정하지 않았습니다.

​	

한편, 26~27행을 통해서는 'data/test_realtime'폴더를 생성했는데,

이는 추후에 영상처리 단계로 넘어갔을 때, 실시간으로 캡쳐되는 이미지가  Resizing된 뒤에 저장되는 폴더입니다.

​	

여기서, 이미지를 Resize하는 이유는 다음과 같습니다.

Kaggle Garbage Dataset으로 학습한 Model을 임의의 사진에 대해 Test하고 싶다면

**Test Image로 사용하려는 임의의 사진을 Train 당시 사용했던 Image의 Size와 동일하게 맞춰야 합니다.**

따라서, Resize 과정이 모델 검증 전에 필수로 수반되어야 하며, 그렇지 않을 경우 에러가 발생하게 됩니다.

​	

정리하자면,

***test*** 	= *Random_Test_Image* 폴더에 넣어준 Garbage Image가 Kaggle Dataset Image와 동일한 사이즈로 Resize된 뒤에 들어가는 폴더

***test_realtime***	=  *RealTime_Test_Image* 폴더에 저장된 캡쳐된 실시간 이미지 1장이 Resize된 뒤에 들어가는 폴더

​	

​	

![image](https://user-images.githubusercontent.com/84533279/174450863-fc39bd48-33f4-4003-89da-15875f5c465e.png)

Image Data를 Garbage Type에 따라, 직전 코드에서 생성한 폴더에 이동시켜주는 부분입니다.

이 14번째 셀이 실행되면, '*dataset_fit*'폴더에는 더이상 Image Data가 존재하지 않게 됩니다.

​	

즉, '*dataset_fit*'폴더에 존재하던 모든 Image Data가 Train / Valid Data와 Garbage Type별로 나뉘어집니다.

Cardboard로 예를 들면, 80%의 데이터는 '*data/train/cardboard*'로, 나머지 20%의 데이터는 '*data/valid/cardboard*'로 이동하게 됩니다.

​	

​	

![image](https://user-images.githubusercontent.com/84533279/174450868-54f932bb-328b-42bd-80b4-5a1466099fb0.png)

여기까지 코드가 정상적으로 실행되었다면,

data폴더 안에는 train/valid/test로 구분이 되어있으며, data/train폴더 안에는 cardboard, plastic, metal로 구분이 되어 있습니다.

즉, data폴더가 학습을 위한 dataset에서 가장 상위 폴더가 되기 때문에 data폴더의 경로를 가져와줍니다.

​	

data폴더의 경로가 중요한 이유는,

Model Training에 들어가기 직전에, **ImageDataBunch**라는 함수를 통해 Train/Valid/Test Data를 정의해주는 코드가 있는데

이때 data폴더의 경로가 함수의 파라미터로 들어가야하기 때문입니다.

​	

​		

##### ■ 5. Test Data Folder Clearing & Test Data Resize

![image](https://user-images.githubusercontent.com/84533279/174450881-064a85ca-9e40-4fc4-b689-56f17ffe9160.png)

기존에 '*data/test*' 폴더에 존재하던 파일이 있다면, 모두 삭제해주고

'*Random_Test_Image*'에 넣어준 임의의 Test Image들을 Kaggle Garbage Dataset과 동일한 사이즈인 (512, 384)로 수정하면서,

Resize된 Image들을 '*data/test*'에 넣어주는 코드입니다.

​	

​	

##### ■ 6. Data Transform by FastAI Library

![image](https://user-images.githubusercontent.com/84533279/174450888-ab615e63-36b0-47e2-a210-6d4c4eb8d83d.png)

모델 학습 과정에서는 *fastAI Library*의 *get_transforms* 함수를 통해 데이터를 상하좌우로 반전시키면서 학습하게 하였으며,

이를 통해 하나의 이미지 데이터라도 다양하고 복잡하게 학습하였습니다.

​	□ get_transforms 함수의 Parameter 설명

​	`do_flip = True` :: Image가 Randomly하게 Flipped되도록 설정	

​	`flip_vert = False` :: Image가 Horizontal하게만 Flip되도록 설정

​	`flip_vert = True` :: 90 Degree간격으로 Horizontal하게, 그리고 Vertical하게 Flip되도록 설정

다음 그림은 get_transforms의 실행 결과 예시 사진입니다.

![image](https://user-images.githubusercontent.com/84533279/174466955-d22aec91-7e1c-4231-b426-ef8d60341702.png)

​		

​		


![image](https://user-images.githubusercontent.com/84533279/174450933-bd2b09fe-900c-4c68-be06-3a2f46cac06b.png)

![image](https://user-images.githubusercontent.com/84533279/174450943-e185b13a-9942-4fe1-8978-330b93937131.png)

ImageDataBunch함수를 통해, 지정된 경로 내의 파일의 이름을 바탕으로 train data/valid data/test data를 정해줍니다.

즉, ImageDataBunch함수를 통해서는 학습할 데이터를 빠르게 생성하고 모델 Training준비를 완료할 수 있습니다.

​	□ get_transforms 함수의 Parameter 설명

​	`path` :: 경로 지정	

​	`train` ::  'path'를 통해 지정된 경로의 하위 Train dataset의 폴더명 지정

​	`valid` ::  'path'를 통해 지정된 경로의 하위 Valid dataset의 폴더명 지정

​	`test` ::  'path'를 통해 지정된 경로의 하위 Test dataset의 폴더명 지정

​	`ds_tfms` ::  데이터셋 변형 형식 지정

​	`bs` ::  배치사이즈 지정

​	

본 프로젝트에서는,

train data를 담고 있는 폴더의 이름을 train으로 지정하였으며,

valid data를 담고 있는 폴더의 이름을 valid로 지정하였기에

ImageDataBunch.from_folder함수에서 train parameter와 valid parameter를 따로 지정을 하지 않아도 된다.

​	

단, test data의 경우에는 본 이미지 학습 과정에서는 'test' 폴더를 사용하지만

실시간 영상 처리 과정에서는 'test_realtime'폴더를 사용해서 Classification과 Prediction을 진행해야 하므로

*test = 'test*' 라고 별도로 파일을 지정해주었다.

​	

​	

##### ■ 7. Model Training by Resnet34

![image](https://user-images.githubusercontent.com/84533279/174450948-20f49435-4791-4541-af92-41da8ad26de5.png)

본 프로젝트의 Model training에서는 resnet34을 이용하였습니다.

**NVIDIA GeForce RTX 3060 Laptop GPU cuda device** 환경에서 1 epoch에 약 1분 20초가 소모되었습니다.

따라서, *위와 같은 고성능의 GPU환경이 아니라면 Colab을 사용하시길 권장합니다.* 

​	

참고로, 최적의 Learning Rate를 찾기 위해 본 프로젝트에서는 다음의 코드를 이용하였습니다.

```python
learn.lr_find(start_lr=1e-6, end_lr=1e1)
learn.recorder.plot(suggestion=True)
```

​	

위의 코드를 실행하면 다음과 같은 그래프를 확인할 수 있습니다.

![image](https://user-images.githubusercontent.com/84533279/174468366-99c7b5dc-fdd3-498e-ade1-0346d47cf475.png)

이를 통해,  Loss가 최소가 될 수 있는 적절한 Learning Rate(=약 0.01)를 찾을 수 있으며, 이 값을 추후 Model Training에 이용하였습니다.



단, Learning Rate를 찾는 과정은 시간이 다소 오래 걸리기도 했으며, 최초 1회 실행을 통해 찾아낸 값을 이후에도 사용하면 되었기에

본 프로젝트에서 공개해놓은 **[1. Get_Model_Garbage_Three_Class_Classification.ipynb](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project %232/2. Garbage_Classification_ImageProcessing/1. Get_Model_Garbage_Three_Class_Classification.ipynb)** 파일에는 이 부분을 제거하였습니다.

​	

​	

![image](https://user-images.githubusercontent.com/84533279/174450957-1d8f7af4-60ed-442b-b85f-7048fdd3772e.png)

학습된 Model을 TrainData에 대해 적용해본 결과 96.9%의 분류 정확도를 보였습니다.

​	

​	

##### ■ 8. Apply Model to Resized Test Data

Model이 Train Image Data에 Over-fitting되지는 않았는지 확인하기 위해 *Galaxy S10 Camera* 를 통해 촬영한 10개의 사진으로 모델의 성능을 확인하였습니다.

​	

*get_preds* 함수를 통해 10개의 Test Image Data에 대해 예측 확률을 반환하도록 하였습니다. 

[0.8, 0.15, 0.05]라면 Cardboard일 확률이 80%, Metal일 확률이 15%, Plastic일 확률이 5%라는 의미입니다.

![image](https://user-images.githubusercontent.com/84533279/174450963-0bc61ddb-6415-4a38-9862-635f6019b50b.png)

​	

​	

3가지 Class에 대한 확률값에서, 가장 확률이 높은 인덱스를 추출하였습니다.

그리고, *data.classes* 함수를 통해 인덱스에 대응되는 class label을 붙여주었습니다.

![image](https://user-images.githubusercontent.com/84533279/174450975-1ab5221a-d1d3-446c-830b-2935dc240c60.png)

이를 통해, 첫번째 Test Image의 예측값은 'Cardboard'임을 확인할 수 있습니다.

​	

​	

Train된 Model이 알맞게 예측했는지 시각적으로 확인하기 위해,

첫번째 Test Image를 확인하였습니다.

![image](https://user-images.githubusercontent.com/84533279/174450986-7f029986-aead-45cc-9511-817da91482b4.png)

이를 통해, Model Training이 잘 이루어졌다고 판단할 수 있으며,

마지막으로, 다른 Test Image에 대해서는 어떻게 예측했는지 확인함으로써 Model의 성능을 최종 평가해보도록 하겠습니다.

​	

​	

모든 Test Image Data의 경로를 가져옵니다. 경로의 끝을 보면, 파일의 이름이 ' **Type이름 + Index Number.jpg** '로 설정했던 것을 확인할 수 있습니다.

즉, 저장해둔 파일 이름으로 부터, Test Image에 대해 Labeling이 가능합니다.

이를 메타 문자 기능을 사용하여, Index Number가 나오기 전 문자 까지만 추출하도록 함으로써 Test Image의 정답 데이터를 가져왔습니다.

![image](https://user-images.githubusercontent.com/84533279/174450993-bad516f4-a2d6-4b55-b28e-9c65f793e59c.png)

​	

​	

Test Image의 실제 정답과 Train된 Model로 예측한 값이 동일함을 확인할 수 있습니다.

![image](https://user-images.githubusercontent.com/84533279/174450996-f0a0abc6-d0bc-4c35-9f0b-3128064902f9.png)

![image](https://user-images.githubusercontent.com/84533279/174451006-752ad30f-bcf4-4f72-a122-0e992d574c4c.png)

![image](https://user-images.githubusercontent.com/84533279/174451009-8b2d506b-5efe-4dcf-b766-07835499c2a4.png)

이와 같이, 임의로 촬영한 무작위 Garbage Image 10개에 대해 100%의 분류 정확도를 보였기 때문에

Training이 잘 이루어졌다고 판단하였으며, 이 Model을 이용하여 실시간 영상 처리에 적용해도 문제가 없다고 판단하였습니다.

​		

​	

##### ■ 9. Model Save

따라서, 위 모델을 다음과 같이 저장하였습니다.

참고로, 이렇게 저장한 모델은 '*data/models/*'에 저장됩니다.

![image](https://user-images.githubusercontent.com/84533279/174451013-e462179f-87df-41f0-9692-a7bc4b641aee.png)

​	

​	

​	

## Real-time Web-cam Garbage Classification with Pre-Trained Model

**[1. Get_Model_Garbage_Three_Class_Classification.ipynb](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project %232/2. Garbage_Classification_ImageProcessing/1. Get_Model_Garbage_Three_Class_Classification.ipynb)** 을 통해,

분류 정확로 96.9%의 우수한 Garbage Classification Model을 만들었기에, 이를 실시간 영상 처리에 활용하였습니다.



관련 코드는 **[2. Realtime_Webcam_Garbage_Classification.ipynb](https://github.com/Hongsehyun/2022_1_DigitalTwin_Automation/blob/main/Project %232/2. Garbage_Classification_ImageProcessing/2. Realtime_Webcam_Garbage_Classification.ipynb)** 에서 다운로드 및 확인하실 수 있으며,

다운로드 받으시면 pre-trained된 model이 담겨져있는 '*data*'폴더와 동일한 경로에 옮겨주시면 됩니다.







![image](https://user-images.githubusercontent.com/84533279/174451370-4bbda429-23d0-4b6b-beae-cda10d97234c.png)


![image](https://user-images.githubusercontent.com/84533279/174451039-c9ad145f-5a34-4e86-b6db-88d3497c59b9.png)

![image](https://user-images.githubusercontent.com/84533279/174451470-5cf95f7c-a9e9-48fd-9b26-ecbddd9ccced.png)

![image](https://user-images.githubusercontent.com/84533279/174451496-bcee924e-8e37-4888-835c-df37b7b1e469.png)




![image](https://user-images.githubusercontent.com/84533279/174451060-97f796a2-cb20-47db-a9e7-e84d59dc9d14.png)




![image](https://user-images.githubusercontent.com/84533279/174451076-b4f1ef65-4e0f-41cf-87d3-16da41220a46.png)


![image](https://user-images.githubusercontent.com/84533279/174451102-1a322d13-04e0-4d92-b8c2-104a4b6ce699.png)


![image](https://user-images.githubusercontent.com/84533279/174451110-97fdc0e4-2351-481f-965b-97f5f9ebb326.png)


![image](https://user-images.githubusercontent.com/84533279/174451119-98a4423a-52a1-4bc8-afd3-1f6bf370b51f.png)


![image](https://user-images.githubusercontent.com/84533279/174451122-8d896836-acde-4d0a-b596-0cd7386de0d3.png)


![image](https://user-images.githubusercontent.com/84533279/174451263-a5724b0e-3e8b-4a96-b85c-1b01d75872f1.png)



![image](https://user-images.githubusercontent.com/84533279/174451275-61981146-50e7-43a9-87fd-ee31ebccbbb8.png)

![image](https://user-images.githubusercontent.com/84533279/174451287-bf5f3df3-87fd-41f7-95d1-a7ca18374b26.png)


![image](https://user-images.githubusercontent.com/84533279/174451348-f4a5b2d5-c743-4d4e-8b87-d2491d1d6434.png)

![image](https://user-images.githubusercontent.com/84533279/174469254-b2d11038-bfb6-4ec6-ad8a-0c17a4283386.png)


